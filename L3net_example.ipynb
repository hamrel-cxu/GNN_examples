{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using L3Net (Cheng et. al. 2020)\n",
    "\n",
    "The network below can act as a residual block, as the output dimension matches the input dimension.\n",
    "\n",
    "Note that when instantiating the L3net from its class, we need to pre-specify the adjacency matrix of the graph.\n",
    "\n",
    "Each row of the input tensor is a nodal feature matrix of size $(V,C)$, where $V$ is the number of node and $C$ is input feature dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from L3net import GraphConv_Bases\n",
    "import torch.nn as nn\n",
    "import torch_geometric as pyg\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_tranpose(nn.Module):\n",
    "    def __init__(self, dim0=1, dim1=2):\n",
    "        super().__init__()\n",
    "        self.dim0 = dim0\n",
    "        self.dim1 = dim1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.transpose(x, self.dim0, self.dim1)\n",
    "\n",
    "layers = []\n",
    "for i in range(1):\n",
    "    order_list = [0, 1, 2]\n",
    "    C = 9 # Input feature dimension\n",
    "    dim = 20\n",
    "    # three node graph\n",
    "    # e.g., nodes 0 and 1 are connected, and nodes 1 and 2 are connected\n",
    "    edge_index_tmp = torch.tensor(\n",
    "        [[0, 1, 1, 2, 0, 1, 2], [1, 0, 2, 1, 0, 1, 2]])\n",
    "    # Also supports graph with more than one connected components \n",
    "    # e.g.: nodes 0 and 1 are connected, but node 2 is isolated\n",
    "    edge_index_tmp = torch.tensor(\n",
    "        [[0, 1, 0, 1, 2], [1, 0, 0, 1, 2]])\n",
    "    A_ = pyg.utils.to_dense_adj(edge_index_tmp)[\n",
    "        0].to(device)  # For L3net\n",
    "    act = nn.ReLU()\n",
    "    trans = input_tranpose(1, 2)\n",
    "    layers.append(trans)\n",
    "    layers.append(GraphConv_Bases(C, dim, A_, order_list=order_list))\n",
    "    layers.append(act)\n",
    "    layers.append(GraphConv_Bases(dim, dim, A_, order_list=order_list))\n",
    "    layers.append(trans)\n",
    "    layers.append(act)\n",
    "    layers.append(nn.Linear(dim, dim))\n",
    "    layers.append(act)\n",
    "    layers.append(nn.Linear(dim, C))\n",
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): input_tranpose()\n",
       "  (1): GraphConv_Bases(\n",
       "    (coeff_conv): Conv1d(27, 20, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (2): ReLU()\n",
       "  (3): GraphConv_Bases(\n",
       "    (coeff_conv): Conv1d(60, 20, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (4): input_tranpose()\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=20, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, V = 100, 3\n",
    "x = torch.randn(N, V, C).to(device)\n",
    "y = model(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2b027265654e175564c138f70da2c17536be0994f8fca8d41e08e82b8028e91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
